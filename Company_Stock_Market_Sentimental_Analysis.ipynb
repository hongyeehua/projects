{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Company Stock Market Sentimental Analysis**\n",
        "\n",
        "**Hong Yee (Isaac) Hua**\n",
        "\n",
        "---\n",
        "\n",
        "Tired of sifting through analyst articles to gauge market sentiment and market news on a particular company?\n",
        "\n",
        "**Look no further.**\n",
        "\n",
        "This tool in Python is designed to obtain the most recent view of the market sentiment on a company, with a summarisation of recent market news.\n",
        "\n",
        "\n",
        "\n",
        "**NOTE:** You will need a Cohere API key and an Alpha Vantage API key (obtainable through account creation). Maybe if you, dear reader, can get me a job, then you wouldn't need to provide your own API key.. however, I am but a lowly student with a trial key. Can't exactly process hundreds of articles.\n",
        "\n",
        "## EXAMPLE INPUT AND OUTPUT:\n",
        "\n",
        "\n",
        "\n",
        "> What is your Cohere API key?\n",
        "\n",
        ">TqNim7S803C7Pz7pLmGYb38PZkiDeceA1wkFDDTf\n",
        "\n",
        ">What is your AlphaVantage API key?\n",
        "\n",
        ">KK6JVIIT1YZ51460\n",
        "\n",
        ">What is your prospective company's ticker symbol?\n",
        "\n",
        ">GOOG\n",
        "\n",
        ">How many articles do you want to analyse? (Up to 200 for trial users)\n",
        "\n",
        ">20\n",
        "\n",
        "> Overall recent market sentiment:  \n",
        "\n",
        "> Neutral \n",
        "\n",
        "> Summarization of current market news:  \n",
        "\n",
        "> Alphabet Inc has added a new update to its music app that lets users automatically download recently played songs on Android. The new update allows users to download up to 200 recently played songs. The users may also find this feature already enabled on their devices. Meanwhile, Alphabet has announced that US creators can now create podcasts in YouTube Studio and the inclusion of podcasts in the company's music app is coming soon.\n",
        "\n",
        "---\n",
        "### **How does this work?**\n",
        "\n",
        "Well, I'm glad you asked my friend, it's definitely been a journey to make this function.\n",
        "\n",
        "Essentially,\n",
        "\n",
        "1. Alpha Vantage AI pulls and processes analyst articles on the ticker, through websites such as Bezinga, Zacks etc.\n",
        "2. Each article is processed through Newspaper to be read, and overall market sentiment is averaged out across all the articles through Alpha Vantage's natural language processing model.\n",
        "3. Taking samples of each article, we summarise using Cohere AI's summarisation model. We feed these articles through layers and summarise further, depending on the complexity of articles.\n",
        "4. Our end result is an average sentiment score across all the recent articles (number specified by user) and a final summarised paragraph of the most recent market news on the specified company.\n",
        "\n",
        "Enjoy.\n",
        "\n",
        "---\n",
        "\n",
        "### **Improvements to be made:**\n",
        "- Include foreign companies which are not in US stock market, use a translation model to process articles in foreign languages\n",
        "- Splitting into cases $\\rightarrow$ trial users (more hallucinations for news summarisation) & professional users (more accurate and reliable for news summarisation)\n",
        "- Training model further to more efficiently\n",
        "- Raising appropriate errors when given invalid inputs\n",
        "\n"
      ],
      "metadata": {
        "id": "fhjzyk2t3vSZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOQIySJxVQAV"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# install all libraries\n",
        "!pip install alpha_vantage\n",
        "!pip install requests\n",
        "!pip install newspaper3k\n",
        "!pip install cohere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08L7trBuTkj1"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#imports\n",
        "import nltk\n",
        "import requests\n",
        "nltk.download('punkt')\n",
        "from newspaper import Article\n",
        "import random\n",
        "import cohere\n",
        "from newspaper.images import urllib\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7ZItHaEOTTl",
        "outputId": "aa0d26cc-7c4e-478d-df38-3c07a88d486a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is your Cohere API key?\n",
            "TqNim7S803C7Pz7pLmGYb38PZkiDeceA1wkFDDTf\n",
            "What is your AlphaVantage API key?\n",
            "KK6JVIIT1YZ51460\n",
            "What is your prospective company's ticker symbol?\n",
            "GOOG\n",
            "How many articles do you want to analyse? (Up to 200 for trial users)\n",
            "20\n",
            "\n",
            " Overall recent market sentiment:  \n",
            " Neutral \n",
            " Summarization of current market news:  \n",
            " Alphabet Inc has added a new update to its music app that lets users automatically download recently played songs on Android. The new update allows users to download up to 200 recently played songs. The users may also find this feature already enabled on their devices. Meanwhile, Alphabet has announced that US creators can now create podcasts in YouTube Studio and the inclusion of podcasts in the company's music app is coming soon.\n"
          ]
        }
      ],
      "source": [
        "def get_yahoo_shortname(symbol): #function to lookup company ticker's name\n",
        "    response = urllib.request.urlopen(f'https://query2.finance.yahoo.com/v1/finance/search?q={symbol}')\n",
        "    content = response.read()\n",
        "    company = json.loads(content.decode('utf8'))['quotes'][0]['shortname']\n",
        "    return company\n",
        "\n",
        "def sentimental_analysis(): #big boy function\n",
        "    \"\"\"\n",
        "    Returns sentimental analysis on company ticker, using Cohere and Alpha Vantage.\n",
        "    \"\"\"\n",
        "\n",
        "    cohere_apikey = str(input(\"What is your Cohere API key?\\n\"))\n",
        "    alpha_vantage = str(input(\"What is your AlphaVantage API key?\\n\"))\n",
        "    ticker = str(input(\"What is your prospective company's ticker symbol?\\n\"))\n",
        "    limit = str(input(\"How many articles do you want to analyse? (Up to 200 for trial users)\\n\"))\n",
        "\n",
        "    co = cohere.Client(cohere_apikey)\n",
        "\n",
        "    url = ('https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers=' \n",
        "           + f\"{ticker}\"+ f'&limit={limit}'+ '&apikey=' + f\"{alpha_vantage}\")\n",
        "    r = requests.get(url)\n",
        "    data = r.json()\n",
        "\n",
        "    article_urls = [] #initialising article url list and total ticker sentiment score\n",
        "    total_ticker_sentiment = 0.0\n",
        "\n",
        "    for a in range(0, len(data['feed'])): #Parses through each article\n",
        "        article_urls.append(data['feed'][a]['url']) #Appends url to the list\n",
        "        for t in range(0, len(data['feed'][a]['ticker_sentiment'])): #Parses through ticker list for particular ticker\n",
        "            if data['feed'][a]['ticker_sentiment'][t]['ticker'] == ticker: #Only grab the info about relevant ticker\n",
        "              total_ticker_sentiment += float(data['feed'][a]['ticker_sentiment'][t]['ticker_sentiment_score'])\n",
        "\n",
        "    average_ticker_sentiment = total_ticker_sentiment/len(data['feed'])\n",
        "\n",
        "    if average_ticker_sentiment <= -0.35:\n",
        "      sentiment = \"Bearish\"\n",
        "    elif average_ticker_sentiment <= -0.15:\n",
        "      sentiment = \"Slightly Bearish\"\n",
        "    elif average_ticker_sentiment < 0.15:\n",
        "      sentiment = \"Neutral\"\n",
        "    elif average_ticker_sentiment < 0.35:\n",
        "      sentiment = \"Slightly Bullish\"\n",
        "    else:\n",
        "      sentiment = \"Bullish\" \n",
        "\n",
        "    article_contents = []\n",
        "    company = get_yahoo_shortname(ticker)\n",
        "\n",
        "    for url in article_urls:\n",
        "      try: #Web scraping is not always legal and allowed, so we will do it for websites that allow it.\n",
        "        article = Article(url)\n",
        "        article.download()\n",
        "        article.parse()\n",
        "        article.nlp()\n",
        "        article_contents.append(article.text)\n",
        "      except:\n",
        "        continue #we skip summarizing the articles that do not allow for scraping\n",
        "      \n",
        "# Cutting all this out since I only have trial API key. (Use if premium plan)\n",
        "\n",
        "#    random_list_first = random.sample(range(0,len(article_contents)), \n",
        "#                                      k=(len(article_contents)//5)) #RNG for summarizing\n",
        "   \n",
        "#    summarized_articles = []\n",
        "\n",
        "#    for i in random_list_first: \n",
        "#      response = co.summarize(text=article_contents[i], model='summarize-xlarge', \n",
        "#                                length='long', format=\"paragraph\", temperature=0.1,\n",
        "#                                additional_command=f\"Summarise with the focus on the company: {company}\")\n",
        "#      summarized_articles.append(response.summary)\n",
        "    \n",
        "#    random_list_second = random.sample(range(0,len(summarized_articles)),\n",
        "#                                       k=len((summarized_articles)//2)) #second RNG\n",
        "#    second_random_articles = []\n",
        "\n",
        "#    for i in random_list_second: \n",
        "#      response = co.summarize(text=summarized_articles[i], model='summarize-xlarge', \n",
        "#                                length='long', format=\"paragraph\", temperature=0.1,\n",
        "#                                additional_command=f\"Summarise with the focus on the company: {company}\")\n",
        "#      second_random_articles.append(response.summary)\n",
        "\n",
        "#    random_list_final = random.sample(range(0,len(second_random_articles)),\n",
        "#                                      k=1)\n",
        "    \n",
        "#    for i in random_list_final:\n",
        "#        response = co.summarize(text=second_random_articles[i], model='summarize-xlarge', \n",
        "#                                length='long', format=\"paragraph\", temperature=0.1,\n",
        "#                                additional_command=f\"Summarise with the focus on the company: {company}\")\n",
        "    \n",
        "    random_list_first = random.sample(range(0,len(article_contents)), \n",
        "                                      k=min(3,len(article_contents))) #RNG for summarizing\n",
        "   \n",
        "    summarized_articles = []\n",
        "\n",
        "    for i in random_list_first: \n",
        "      response = co.summarize(text=article_contents[i], model='summarize-xlarge', \n",
        "                                length='long', format=\"paragraph\", temperature=0.1,\n",
        "                                additional_command=f\"Write as an equity research analyst that is researching on the current news of {company}\")\n",
        "      summarized_articles.append(response.summary)\n",
        "    \n",
        "    big_string = summarized_articles[0]\n",
        "\n",
        "    for i in range(1,len(big_string)):\n",
        "      big_string += \"\\n\" #doing this to save on memory\n",
        "      big_string += big_string[i]\n",
        "\n",
        "    response = co.summarize(text=big_string, model='summarize-xlarge', \n",
        "                            length='long', format=\"paragraph\", temperature=0.1,\n",
        "                            additional_command=f\"Write as an equity research analyst that is researching on the current news of {company}\")\n",
        "\n",
        "    return sentiment, response.summary\n",
        "\n",
        "statement = sentimental_analysis()\n",
        "\n",
        "print('\\n', 'Overall recent market sentiment: ',\n",
        "      '\\n', statement[0], '\\n', \n",
        "      'Summarization of current market news: ', '\\n',\n",
        "      statement[1])\n",
        "\n",
        "\n",
        "        \n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}